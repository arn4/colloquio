
\section{Classical training Algorithms}
\subsection{Update Rule}
\begin{frame}
  \frametitle{Update rule}
  Gradient \& some corrections to improve learning:
  \[
  \vec{\theta}^{(t+1)} = \vec{\theta}^{(t)}
  \underbrace{
    \onslide<1->{+ \eta \ParDer{\log\likelihood{\vec{\theta}}{\vec{\bar{v}}}}{\vec{\theta}}}
    \onslide<2->{- \lambda \vec{\theta}^{(t)}}
    \onslide<3->{+ \nu \Delta\vec{\theta}^{(t-1)}}
  \onslide<3->}_{{\coloneqq \Delta\vec{\theta}^{(t)}}}
	\onslide<1->
  \]
  \begin{itemize}
    \item<1-> \structure{Learning rate}: length of the step toward gradient
    \item<2-> \structure{Weight decay}: keeps parameters small
    \item<3-> \structure{Momentum}: avoids fluctuations
    \item<4-> \structure{Batches}: group updates before applying them 
  \end{itemize}
  \onslide<4->{All these are \alert{meta-parameters} of an algorithm:
  \emph{Hinton's guide} \cite{hinton2012practical} for tuning.}
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{MCMC Algorithms}
\begin{frame}
  \frametitle{Naive Gibbs Sampling}
  \begin{alertblock}<1->{Idea!}
    Use a \alert{Markov Chain Monte-Carlo} algorithm that sample \(\prob{\vec{v}}\).\\
    RBM Markov Property \(\implies\) update one layer at a time, not single units.
  \end{alertblock}
  \vfill
  \begin{columns}
    \begin{column}{0.62\textwidth}
    	\onslide<2->
      The algorithm is:
      \begin{enumerate}
        \item Choose visible layer state \(\vec{v}^{(0)}\) randomly.
        \item\label{enm:sample-hidden} Sample an hidden layer state using \(\condprob{h^{(t+1)}_j=1}{\vec{v}^{(t)}}\).
        \item Sample a visible layer state using \(\condprob{v^{(t+1)}_i=1}{\vec{h}^{(t)}}\).
        \item Repeat from step \ref{enm:sample-hidden} until stationary condition is reached
        \item Visible state \(\vec{v}^{(s)}\) is a sample from \(\prob{\vec{v}}\)
      \end{enumerate}
    \end{column}
    \begin{column}{0.35\textwidth}
    	\visible<3->{
	      \begin{alertblock}{Problem!}
	        Reaching stationary distribution is too slow.
	      \end{alertblock}
      }
    \end{column}
  \end{columns}
\end{frame}

\begin{frame}
  \frametitle{Contrastive Divergence}
  \begin{alertblock}<1->{Idea!}
    Training samples are already sampled from the goal distribution, that is also the invariant distribution at the end of the training.\\
  \end{alertblock}
  \vspace{20pt}
  \begin{columns}
    \begin{column}{0.66\textwidth}
    	\onslide<2->
      Algorithm changes:
      \begin{enumerate}
        \item Set \(\vec{v}^{(0)} = \vec{\bar{v}}\), the training  sample.
        \addtocounter{enumi}{2}
        \item Repeat from step 2 for \alert{\(k\) times}
        \item Expected values are estimated using \emph{only} \(\vec{v}^{(k)}\).
      \end{enumerate}
      Two kinds of speed-up:
      \begin{itemize}
        \item \(k\) is fixed (often to 1)
        \item we only use \emph{one} sample from the distribution
      \end{itemize}
    \end{column}
    \begin{column}{0.32\textwidth}
    	\visible<3->{
      	\begin{alertblock}{Drawback!}
        	\(\vec{v}^{(k)}\) is biased\\
        	We are not maximizing the likelihood
      	\end{alertblock}
      }
    \end{column}
  \end{columns}
\end{frame}

\begin{frame}
  \frametitle{Persistent Contrastive Divergence}
  \begin{alertblock}{Ideas!}
    \begin{itemize}
      \item Use the \(\vec{v}^{(k)}\) of the previous update as \(\vec{v}^{(0)}\) for the current one
      \item Use many chains to have a better statistics  when computing expected values
    \end{itemize}
  \end{alertblock}
	\pause
  \begin{alertblock}{Why is it better than CD?}
     Parameters change slightly between two consecutive updates, so only few Markov Chain steps are needed to recover the invariant distribution \\
     At the beginning of learning CD is far from the real invariant distribution 
  \end{alertblock}
	The number of chains is usually the size of the batch.
\end{frame}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Monitoring}
\begin{frame}
  \frametitle{Pseudo-likelihood}

  \begin{alertblock}{Problem!}
    Likelihood is not computable in practice! We can't compute \(Z\)
  \end{alertblock}
	\pause
  \[
    \vec{\bar{v}} \xrightarrow{\text{MC sample}} \vec{\bar{h}} \longrightarrow \log\likelihood{\vec{\theta}}{\vec{\bar{v}}} \approx \log{\condprob{\vec{\bar{v}}}{\vec{\bar{h}}}}
  \]
  \(\condprob{\vec{\bar{v}}}{\vec{\bar{h}}}\) can be easily computed analytically.
\end{frame}
